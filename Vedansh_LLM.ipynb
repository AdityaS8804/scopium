{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "mMaAjOAxvvBW"
      },
      "outputs": [],
      "source": [
        "# !pip install python-arango nx-arangodb langchain_openai langchain_community langchain_mistralai mistralai langgraph"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "20gA1G7f8Y1Q"
      },
      "outputs": [],
      "source": [
        "# !git clone https://github.com/pallets/flask.git"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 32,
      "metadata": {
        "id": "BKvqhSpis1Em"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import re\n",
        "from random import randint\n",
        "import nx_arangodb as nxadb\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "from arango import ArangoClient\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from langchain_core.tools import tool\n",
        "from mistralai import Mistral\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_extraction_chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 33,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SVnLX7MQs35i",
        "outputId": "e10257be-7511-4436-d80e-dc0e6c43723f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "<StandardDatabase _system>\n"
          ]
        }
      ],
      "source": [
        "db = ArangoClient(hosts=\"https://d2eeb8083350.arangodb.cloud:8529\").db(username=\"root\", password=\"cUZ0YaNdcwfUTw6VjRny\", verify=True)\n",
        "\n",
        "print(db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 34,
      "metadata": {
        "id": "5Bddjik3tp8M"
      },
      "outputs": [],
      "source": [
        "arango_graph = ArangoGraph(db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lb4PGjHp9FlW",
        "outputId": "85be6141-b060-4532-aa7b-4ee7dffd8fbf"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "[16:14:38 +0530] [INFO]: Graph 'FlaskRepv1' exists.\n",
            "INFO:nx_arangodb:Graph 'FlaskRepv1' exists.\n",
            "[16:14:39 +0530] [INFO]: Default node type set to 'FlaskRepv1_node'\n",
            "INFO:nx_arangodb:Default node type set to 'FlaskRepv1_node'\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Graph named 'FlaskRepv1' with 2975 nodes and 8652 edges\n"
          ]
        }
      ],
      "source": [
        "G_adb = nxadb.Graph(\n",
        "    name=\"FlaskRepv1\",\n",
        "    db=db,\n",
        "    #incoming_graph_data=G,\n",
        "    #write_batch_size=50000 # feel free to modify\n",
        ")\n",
        "\n",
        "print(G_adb)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "coPr-NBb9J-5",
        "outputId": "8ce73319-403d-4b11-826a-b08bf39175be"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "{'Graph Schema': [{'graph_name': 'CodebaseGraph',\n",
              "   'edge_definitions': [{'edge_collection': 'CodebaseGraph_node_to_CodebaseGraph_node',\n",
              "     'from_vertex_collections': ['CodebaseGraph_node'],\n",
              "     'to_vertex_collections': ['CodebaseGraph_node']}]},\n",
              "  {'graph_name': 'FlaskRepv1_node_to_FlaskRespv1_node',\n",
              "   'edge_definitions': [{'edge_collection': 'FlaskRepv1_node_to_FlaskRespv1_node_node_to_FlaskRepv1_node_to_FlaskRespv1_node_node',\n",
              "     'from_vertex_collections': ['FlaskRepv1_node_to_FlaskRespv1_node_node'],\n",
              "     'to_vertex_collections': ['FlaskRepv1_node_to_FlaskRespv1_node_node']}]},\n",
              "  {'graph_name': 'FlaskRepv1_node',\n",
              "   'edge_definitions': [{'edge_collection': 'FlaskRepv1_node_node_to_FlaskRepv1_node_node',\n",
              "     'from_vertex_collections': ['FlaskRepv1_node_node'],\n",
              "     'to_vertex_collections': ['FlaskRepv1_node_node']}]},\n",
              "  {'graph_name': 'FlaskRepv1',\n",
              "   'edge_definitions': [{'edge_collection': 'FlaskRepv1_node_to_FlaskRepv1_node',\n",
              "     'from_vertex_collections': ['FlaskRepv1_node'],\n",
              "     'to_vertex_collections': ['FlaskRepv1_node']}]}],\n",
              " 'Collection Schema': [{'collection_name': 'FlaskRepv1_node',\n",
              "   'collection_type': 'document',\n",
              "   'document_properties': [{'name': '_key', 'type': 'str'},\n",
              "    {'name': '_id', 'type': 'str'},\n",
              "    {'name': '_rev', 'type': 'str'},\n",
              "    {'name': 'type', 'type': 'str'},\n",
              "    {'name': 'file_index', 'type': 'int'},\n",
              "    {'name': 'directory', 'type': 'str'}],\n",
              "   'example_document': {'_key': '0',\n",
              "    '_id': 'FlaskRepv1_node/0',\n",
              "    '_rev': '_jTEM05e---',\n",
              "    'type': 'file',\n",
              "    'file_index': 1,\n",
              "    'directory': 'examples/javascript/tests'}},\n",
              "  {'collection_name': 'FlaskRepv1_node_to_FlaskRepv1_node',\n",
              "   'collection_type': 'edge',\n",
              "   'edge_properties': [{'name': '_key', 'type': 'str'},\n",
              "    {'name': '_id', 'type': 'str'},\n",
              "    {'name': '_from', 'type': 'str'},\n",
              "    {'name': '_to', 'type': 'str'},\n",
              "    {'name': '_rev', 'type': 'str'},\n",
              "    {'name': 'edge_type', 'type': 'str'},\n",
              "    {'name': 'start_line', 'type': 'int'},\n",
              "    {'name': 'end_line', 'type': 'int'}],\n",
              "   'example_edge': {'_key': '0',\n",
              "    '_id': 'FlaskRepv1_node_to_FlaskRepv1_node/0',\n",
              "    '_from': 'FlaskRepv1_node/0',\n",
              "    '_to': 'FlaskRepv1_node/1',\n",
              "    '_rev': '_jTEM1RG---',\n",
              "    'edge_type': 'contains_snippet',\n",
              "    'start_line': 1,\n",
              "    'end_line': 15}}]}"
            ]
          },
          "execution_count": 20,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "arango_graph = ArangoGraph(db)\n",
        "arango_graph.schema"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Found 0 occurrences of test_tag_interface() function:\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "[]"
            ]
          },
          "execution_count": 40,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "def find_test_tag_interface_function(db, verbose=True):\n",
        "    \"\"\"\n",
        "    Search for the test_tag_interface() function in the ArangoDB codebase.\n",
        "    \n",
        "    Args:\n",
        "        db: The ArangoDB database connection object\n",
        "        verbose: Whether to print results as they're found\n",
        "    \n",
        "    Returns:\n",
        "        A list of dictionaries containing the search results\n",
        "    \"\"\"\n",
        "    # Query to search for the test_tag_interface() function\n",
        "    query = \"\"\"\n",
        "    // Try main collection first\n",
        "    LET main_results = (\n",
        "        FOR doc IN FlaskRepv1_node\n",
        "            FILTER CONTAINS(doc.content, \"test_tag_interface()\")\n",
        "            LET pos = POSITION(doc.content, \"test_tag_interface()\")\n",
        "            LET start_pos = pos > 100 ? pos - 100 : 0\n",
        "            LET content_preview = SUBSTRING(doc.content, start_pos, 300)\n",
        "            RETURN {\n",
        "                collection: \"FlaskRepv1_node\",\n",
        "                document_id: doc._id,\n",
        "                file_path: doc.directory,\n",
        "                file_index: doc.file_index,\n",
        "                content_preview: content_preview\n",
        "            }\n",
        "    )\n",
        "    \n",
        "    // Try other collections if no results found\n",
        "    LET other_results = (\n",
        "        LENGTH(main_results) == 0 ? (\n",
        "            FOR collection IN [\"CodebaseGraph_node\", \"FlaskRepv1_node_to_FlaskRespv1_node_node\", \"FlaskRepv1_node_node\"]\n",
        "                FOR doc IN @@collection\n",
        "                    FILTER IS_DOCUMENT(doc) AND HAS(doc, \"content\") AND CONTAINS(doc.content, \"test_tag_interface()\")\n",
        "                    LET pos = POSITION(doc.content, \"test_tag_interface()\")\n",
        "                    LET start_pos = pos > 100 ? pos - 100 : 0\n",
        "                    LET content_preview = SUBSTRING(doc.content, start_pos, 300)\n",
        "                    RETURN {\n",
        "                        collection: collection,\n",
        "                        document_id: doc._id,\n",
        "                        file_path: HAS(doc, \"directory\") ? doc.directory : null,\n",
        "                        file_index: HAS(doc, \"file_index\") ? doc.file_index : null,\n",
        "                        content_preview: content_preview\n",
        "                    }\n",
        "        ) : []\n",
        "    )\n",
        "    \n",
        "    // Combine results\n",
        "    LET all_results = APPEND(main_results, other_results)\n",
        "    \n",
        "    // If function found, check for related nodes in graph\n",
        "    LET graph_results = (\n",
        "        LENGTH(all_results) > 0 ? (\n",
        "            FOR hit IN all_results\n",
        "                LET doc = DOCUMENT(hit.document_id)\n",
        "                LET connected = (\n",
        "                    FOR v, e IN 1..2 OUTBOUND doc FlaskRepv1_node_to_FlaskRepv1_node\n",
        "                    RETURN {\n",
        "                        related_id: v._id,\n",
        "                        relationship: e.edge_type,\n",
        "                        related_type: HAS(v, \"type\") ? v.type : null,\n",
        "                        preview: HAS(v, \"content\") ? SUBSTRING(v.content, 0, 150) : null\n",
        "                    }\n",
        "                )\n",
        "                RETURN MERGE(hit, {related_nodes: connected})\n",
        "        ) : all_results\n",
        "    )\n",
        "    \n",
        "    RETURN graph_results\n",
        "    \"\"\"\n",
        "    \n",
        "    try:\n",
        "        # Execute the query\n",
        "        cursor = db.aql.execute(query, bind_vars={\"@collection\": \"FlaskRepv1_node\"})\n",
        "        results = [doc for doc in cursor]\n",
        "        \n",
        "        # Flatten results (the query returns a list of lists)\n",
        "        if results and isinstance(results[0], list):\n",
        "            results = results[0]\n",
        "        \n",
        "        # Print results if verbose\n",
        "        if verbose:\n",
        "            print(f\"Found {len(results)} occurrences of test_tag_interface() function:\")\n",
        "            for i, result in enumerate(results, 1):\n",
        "                print(f\"\\n--- Result {i} ---\")\n",
        "                print(f\"Collection: {result.get('collection')}\")\n",
        "                print(f\"Document ID: {result.get('document_id')}\")\n",
        "                print(f\"File Path: {result.get('file_path')}\")\n",
        "                print(f\"File Index: {result.get('file_index')}\")\n",
        "                print(f\"\\nContent Preview:\")\n",
        "                print(f\"```\\n{result.get('content_preview')}\\n```\")\n",
        "                \n",
        "                # Print related nodes if available\n",
        "                if 'related_nodes' in result and result['related_nodes']:\n",
        "                    print(f\"\\nRelated Nodes ({len(result['related_nodes'])}):\")\n",
        "                    for j, node in enumerate(result['related_nodes'][:3], 1):  # Show only first 3 related nodes\n",
        "                        print(f\"  {j}. {node.get('related_id')} ({node.get('relationship')})\")\n",
        "                    \n",
        "                    if len(result['related_nodes']) > 3:\n",
        "                        print(f\"  ... and {len(result['related_nodes']) - 3} more related nodes\")\n",
        "        \n",
        "        return results\n",
        "            \n",
        "    except Exception as e:\n",
        "        print(f\"Error executing ArangoDB query: {str(e)}\")\n",
        "        return []\n",
        "\n",
        "# Example usage:\n",
        "# from arango import ArangoClient\n",
        "# \n",
        "# # Connect to ArangoDB\n",
        "# client = ArangoClient(hosts=\"http://localhost:8529\")\n",
        "# db = client.db(\"_system\", username=\"root\", password=\"your_password\")\n",
        "# \n",
        "# # Find the test_tag_interface() function\n",
        "find_test_tag_interface_function(db)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "YZUnsr_strl3"
      },
      "outputs": [],
      "source": [
        "os.environ[\"MISTRAL_API_KEY\"]=\"jJAuJZkjVcy2ynUhan375sHNviHiBeJU\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IHfzlhH6t4Wp"
      },
      "outputs": [],
      "source": [
        "llm = ChatMistralAI(\n",
        "    model=\"mistral-large-latest\",\n",
        "    temperature=0,\n",
        "    max_retries=2,\n",
        "    api_key = os.environ[\"MISTRAL_API_KEY\"]\n",
        ")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 29,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yXWs8O0_8DU_",
        "outputId": "509ba9c9-0de8-4d45-b264-37ebd4485b8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Repository RAG System Demo\n",
            "==================================================\n",
            "\n",
            "Test Query 1: Explain me the test_tag_interface() function in the codebase?\n",
            "--------------------------------------------------\n",
            "\n",
            "\n",
            "\u001b[1m> Entering new ArangoGraphQAChain chain...\u001b[0m\n",
            "AQL Query (1):\u001b[32;1m\u001b[1;3m\n",
            "WITH FlaskRepv1_node, FlaskRepv1_node_to_FlaskRepv1_node\n",
            "FOR vertex IN FlaskRepv1_node\n",
            "  FILTER vertex.type == 'function' && vertex.name == 'test_tag_interface'\n",
            "  RETURN vertex\n",
            "\u001b[0m\n",
            "AQL Result:\n",
            "\u001b[32;1m\u001b[1;3m[]\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n"
          ]
        },
        {
          "ename": "HTTPStatusError",
          "evalue": "Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mHTTPStatusError\u001b[0m                           Traceback (most recent call last)",
            "Cell \u001b[0;32mIn[29], line 386\u001b[0m\n\u001b[1;32m    384\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124mTest Query \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mquery\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    385\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m-\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n\u001b[0;32m--> 386\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[43mhandle_repository_query\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mResponse: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    388\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m=\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m*\u001b[39m \u001b[38;5;241m50\u001b[39m)\n",
            "Cell \u001b[0;32mIn[29], line 366\u001b[0m, in \u001b[0;36mhandle_repository_query\u001b[0;34m(user_query)\u001b[0m\n\u001b[1;32m    364\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Process user queries about the repository\"\"\"\u001b[39;00m\n\u001b[1;32m    365\u001b[0m agent \u001b[38;5;241m=\u001b[39m create_rag_agent()\n\u001b[0;32m--> 366\u001b[0m result \u001b[38;5;241m=\u001b[39m \u001b[43magent\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\n\u001b[1;32m    367\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\n\u001b[1;32m    368\u001b[0m \u001b[43m        \u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrole\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43muser\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcontent\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43muser_query\u001b[49m\u001b[43m}\u001b[49m\n\u001b[1;32m    369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    370\u001b[0m \u001b[43m\u001b[49m\u001b[43m}\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    371\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m result[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m][\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mcontent\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2367\u001b[0m, in \u001b[0;36mPregel.invoke\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, **kwargs)\u001b[0m\n\u001b[1;32m   2365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m   2366\u001b[0m     chunks \u001b[38;5;241m=\u001b[39m []\n\u001b[0;32m-> 2367\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m chunk \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstream(\n\u001b[1;32m   2368\u001b[0m     \u001b[38;5;28minput\u001b[39m,\n\u001b[1;32m   2369\u001b[0m     config,\n\u001b[1;32m   2370\u001b[0m     stream_mode\u001b[38;5;241m=\u001b[39mstream_mode,\n\u001b[1;32m   2371\u001b[0m     output_keys\u001b[38;5;241m=\u001b[39moutput_keys,\n\u001b[1;32m   2372\u001b[0m     interrupt_before\u001b[38;5;241m=\u001b[39minterrupt_before,\n\u001b[1;32m   2373\u001b[0m     interrupt_after\u001b[38;5;241m=\u001b[39minterrupt_after,\n\u001b[1;32m   2374\u001b[0m     debug\u001b[38;5;241m=\u001b[39mdebug,\n\u001b[1;32m   2375\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs,\n\u001b[1;32m   2376\u001b[0m ):\n\u001b[1;32m   2377\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m stream_mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   2378\u001b[0m         latest \u001b[38;5;241m=\u001b[39m chunk\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langgraph/pregel/__init__.py:2024\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   2018\u001b[0m     \u001b[38;5;66;03m# Similarly to Bulk Synchronous Parallel / Pregel model\u001b[39;00m\n\u001b[1;32m   2019\u001b[0m     \u001b[38;5;66;03m# computation proceeds in steps, while there are channel updates.\u001b[39;00m\n\u001b[1;32m   2020\u001b[0m     \u001b[38;5;66;03m# Channel updates from step N are only visible in step N+1\u001b[39;00m\n\u001b[1;32m   2021\u001b[0m     \u001b[38;5;66;03m# channels are guaranteed to be immutable for the duration of the step,\u001b[39;00m\n\u001b[1;32m   2022\u001b[0m     \u001b[38;5;66;03m# with channel updates applied only at the transition between steps.\u001b[39;00m\n\u001b[1;32m   2023\u001b[0m     \u001b[38;5;28;01mwhile\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mtick(input_keys\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minput_channels):\n\u001b[0;32m-> 2024\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m _ \u001b[38;5;129;01min\u001b[39;00m runner\u001b[38;5;241m.\u001b[39mtick(\n\u001b[1;32m   2025\u001b[0m             loop\u001b[38;5;241m.\u001b[39mtasks\u001b[38;5;241m.\u001b[39mvalues(),\n\u001b[1;32m   2026\u001b[0m             timeout\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstep_timeout,\n\u001b[1;32m   2027\u001b[0m             retry_policy\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mretry_policy,\n\u001b[1;32m   2028\u001b[0m             get_waiter\u001b[38;5;241m=\u001b[39mget_waiter,\n\u001b[1;32m   2029\u001b[0m         ):\n\u001b[1;32m   2030\u001b[0m             \u001b[38;5;66;03m# emit output\u001b[39;00m\n\u001b[1;32m   2031\u001b[0m             \u001b[38;5;28;01myield from\u001b[39;00m output()\n\u001b[1;32m   2032\u001b[0m \u001b[38;5;66;03m# emit output\u001b[39;00m\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langgraph/pregel/runner.py:230\u001b[0m, in \u001b[0;36mPregelRunner.tick\u001b[0;34m(self, tasks, reraise, timeout, retry_policy, get_waiter)\u001b[0m\n\u001b[1;32m    228\u001b[0m t \u001b[38;5;241m=\u001b[39m tasks[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    229\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 230\u001b[0m     \u001b[43mrun_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    231\u001b[0m \u001b[43m        \u001b[49m\u001b[43mt\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    232\u001b[0m \u001b[43m        \u001b[49m\u001b[43mretry_policy\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    233\u001b[0m \u001b[43m        \u001b[49m\u001b[43mconfigurable\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m{\u001b[49m\n\u001b[1;32m    234\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_SEND\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwriter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    235\u001b[0m \u001b[43m            \u001b[49m\u001b[43mCONFIG_KEY_CALL\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcall\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    236\u001b[0m \u001b[43m        \u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    237\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcommit(t, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[1;32m    239\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langgraph/pregel/retry.py:40\u001b[0m, in \u001b[0;36mrun_with_retry\u001b[0;34m(task, retry_policy, configurable)\u001b[0m\n\u001b[1;32m     38\u001b[0m     task\u001b[38;5;241m.\u001b[39mwrites\u001b[38;5;241m.\u001b[39mclear()\n\u001b[1;32m     39\u001b[0m     \u001b[38;5;66;03m# run the task\u001b[39;00m\n\u001b[0;32m---> 40\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mproc\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtask\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minput\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ParentCommand \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[1;32m     42\u001b[0m     ns: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m config[CONF][CONFIG_KEY_CHECKPOINT_NS]\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:546\u001b[0m, in \u001b[0;36mRunnableSeq.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    542\u001b[0m config \u001b[38;5;241m=\u001b[39m patch_config(\n\u001b[1;32m    543\u001b[0m     config, callbacks\u001b[38;5;241m=\u001b[39mrun_manager\u001b[38;5;241m.\u001b[39mget_child(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mseq:step:\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mi\u001b[38;5;250m \u001b[39m\u001b[38;5;241m+\u001b[39m\u001b[38;5;250m \u001b[39m\u001b[38;5;241m1\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    544\u001b[0m )\n\u001b[1;32m    545\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m i \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 546\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    547\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    548\u001b[0m     \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m step\u001b[38;5;241m.\u001b[39minvoke(\u001b[38;5;28minput\u001b[39m, config)\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langgraph/utils/runnable.py:302\u001b[0m, in \u001b[0;36mRunnableCallable.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m    300\u001b[0m     context \u001b[38;5;241m=\u001b[39m copy_context()\n\u001b[1;32m    301\u001b[0m     context\u001b[38;5;241m.\u001b[39mrun(_set_config_context, child_config)\n\u001b[0;32m--> 302\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    303\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    304\u001b[0m     run_manager\u001b[38;5;241m.\u001b[39mon_chain_error(e)\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langgraph/prebuilt/chat_agent_executor.py:621\u001b[0m, in \u001b[0;36mcreate_react_agent.<locals>.call_model\u001b[0;34m(state, config)\u001b[0m\n\u001b[1;32m    619\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcall_model\u001b[39m(state: AgentState, config: RunnableConfig) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m AgentState:\n\u001b[1;32m    620\u001b[0m     _validate_chat_history(state[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmessages\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m--> 621\u001b[0m     response \u001b[38;5;241m=\u001b[39m cast(AIMessage, \u001b[43mmodel_runnable\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstate\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    622\u001b[0m     \u001b[38;5;66;03m# add agent name to the AIMessage\u001b[39;00m\n\u001b[1;32m    623\u001b[0m     response\u001b[38;5;241m.\u001b[39mname \u001b[38;5;241m=\u001b[39m name\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:3029\u001b[0m, in \u001b[0;36mRunnableSequence.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   3027\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m context\u001b[38;5;241m.\u001b[39mrun(step\u001b[38;5;241m.\u001b[39minvoke, \u001b[38;5;28minput\u001b[39m, config, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m   3028\u001b[0m         \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 3029\u001b[0m             \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mcontext\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstep\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   3030\u001b[0m \u001b[38;5;66;03m# finish the root run\u001b[39;00m\n\u001b[1;32m   3031\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langchain_core/runnables/base.py:5365\u001b[0m, in \u001b[0;36mRunnableBindingBase.invoke\u001b[0;34m(self, input, config, **kwargs)\u001b[0m\n\u001b[1;32m   5359\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m   5360\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m   5361\u001b[0m     \u001b[38;5;28minput\u001b[39m: Input,\n\u001b[1;32m   5362\u001b[0m     config: Optional[RunnableConfig] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m   5363\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Optional[Any],\n\u001b[1;32m   5364\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Output:\n\u001b[0;32m-> 5365\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbound\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43minvoke\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   5366\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5367\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_merge_configs\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5368\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43m{\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   5369\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:285\u001b[0m, in \u001b[0;36mBaseChatModel.invoke\u001b[0;34m(self, input, config, stop, **kwargs)\u001b[0m\n\u001b[1;32m    274\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21minvoke\u001b[39m(\n\u001b[1;32m    275\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    276\u001b[0m     \u001b[38;5;28minput\u001b[39m: LanguageModelInput,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    280\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    281\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m BaseMessage:\n\u001b[1;32m    282\u001b[0m     config \u001b[38;5;241m=\u001b[39m ensure_config(config)\n\u001b[1;32m    283\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m cast(\n\u001b[1;32m    284\u001b[0m         ChatGeneration,\n\u001b[0;32m--> 285\u001b[0m         \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate_prompt\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    286\u001b[0m \u001b[43m            \u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_convert_input\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    287\u001b[0m \u001b[43m            \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    288\u001b[0m \u001b[43m            \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcallbacks\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    289\u001b[0m \u001b[43m            \u001b[49m\u001b[43mtags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mtags\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    290\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmetadata\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    291\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_name\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_name\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    292\u001b[0m \u001b[43m            \u001b[49m\u001b[43mrun_id\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrun_id\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    293\u001b[0m \u001b[43m            \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    294\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mgenerations[\u001b[38;5;241m0\u001b[39m][\u001b[38;5;241m0\u001b[39m],\n\u001b[1;32m    295\u001b[0m     )\u001b[38;5;241m.\u001b[39mmessage\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:861\u001b[0m, in \u001b[0;36mBaseChatModel.generate_prompt\u001b[0;34m(self, prompts, stop, callbacks, **kwargs)\u001b[0m\n\u001b[1;32m    853\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mgenerate_prompt\u001b[39m(\n\u001b[1;32m    854\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    855\u001b[0m     prompts: \u001b[38;5;28mlist\u001b[39m[PromptValue],\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    858\u001b[0m     \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: Any,\n\u001b[1;32m    859\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m LLMResult:\n\u001b[1;32m    860\u001b[0m     prompt_messages \u001b[38;5;241m=\u001b[39m [p\u001b[38;5;241m.\u001b[39mto_messages() \u001b[38;5;28;01mfor\u001b[39;00m p \u001b[38;5;129;01min\u001b[39;00m prompts]\n\u001b[0;32m--> 861\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprompt_messages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcallbacks\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:691\u001b[0m, in \u001b[0;36mBaseChatModel.generate\u001b[0;34m(self, messages, stop, callbacks, tags, metadata, run_name, run_id, **kwargs)\u001b[0m\n\u001b[1;32m    688\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i, m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(messages):\n\u001b[1;32m    689\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m    690\u001b[0m         results\u001b[38;5;241m.\u001b[39mappend(\n\u001b[0;32m--> 691\u001b[0m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    692\u001b[0m \u001b[43m                \u001b[49m\u001b[43mm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    693\u001b[0m \u001b[43m                \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    694\u001b[0m \u001b[43m                \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_managers\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mrun_managers\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    695\u001b[0m \u001b[43m                \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    696\u001b[0m \u001b[43m            \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    697\u001b[0m         )\n\u001b[1;32m    698\u001b[0m     \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    699\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m run_managers:\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langchain_core/language_models/chat_models.py:926\u001b[0m, in \u001b[0;36mBaseChatModel._generate_with_cache\u001b[0;34m(self, messages, stop, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    924\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    925\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m inspect\u001b[38;5;241m.\u001b[39msignature(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate)\u001b[38;5;241m.\u001b[39mparameters\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrun_manager\u001b[39m\u001b[38;5;124m\"\u001b[39m):\n\u001b[0;32m--> 926\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_generate\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    927\u001b[0m \u001b[43m            \u001b[49m\u001b[43mmessages\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstop\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mstop\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    928\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    929\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    930\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_generate(messages, stop\u001b[38;5;241m=\u001b[39mstop, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langchain_mistralai/chat_models.py:547\u001b[0m, in \u001b[0;36mChatMistralAI._generate\u001b[0;34m(self, messages, stop, run_manager, stream, **kwargs)\u001b[0m\n\u001b[1;32m    545\u001b[0m message_dicts, params \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_message_dicts(messages, stop)\n\u001b[1;32m    546\u001b[0m params \u001b[38;5;241m=\u001b[39m {\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mparams, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs}\n\u001b[0;32m--> 547\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompletion_with_retry\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    548\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmessages\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmessage_dicts\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrun_manager\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrun_manager\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mparams\u001b[49m\n\u001b[1;32m    549\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    550\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_create_chat_result(response)\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langchain_mistralai/chat_models.py:466\u001b[0m, in \u001b[0;36mChatMistralAI.completion_with_retry\u001b[0;34m(self, run_manager, **kwargs)\u001b[0m\n\u001b[1;32m    463\u001b[0m         _raise_on_error(response)\n\u001b[1;32m    464\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n\u001b[0;32m--> 466\u001b[0m rtn \u001b[38;5;241m=\u001b[39m \u001b[43m_completion_with_retry\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    467\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m rtn\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langchain_mistralai/chat_models.py:463\u001b[0m, in \u001b[0;36mChatMistralAI.completion_with_retry.<locals>._completion_with_retry\u001b[0;34m(**kwargs)\u001b[0m\n\u001b[1;32m    461\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    462\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclient\u001b[38;5;241m.\u001b[39mpost(url\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/chat/completions\u001b[39m\u001b[38;5;124m\"\u001b[39m, json\u001b[38;5;241m=\u001b[39mkwargs)\n\u001b[0;32m--> 463\u001b[0m     \u001b[43m_raise_on_error\u001b[49m\u001b[43m(\u001b[49m\u001b[43mresponse\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    464\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m response\u001b[38;5;241m.\u001b[39mjson()\n",
            "File \u001b[0;32m~/GitHub/scopium/.venv/lib/python3.10/site-packages/langchain_mistralai/chat_models.py:170\u001b[0m, in \u001b[0;36m_raise_on_error\u001b[0;34m(response)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mcodes\u001b[38;5;241m.\u001b[39mis_error(response\u001b[38;5;241m.\u001b[39mstatus_code):\n\u001b[1;32m    169\u001b[0m     error_message \u001b[38;5;241m=\u001b[39m response\u001b[38;5;241m.\u001b[39mread()\u001b[38;5;241m.\u001b[39mdecode(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mutf-8\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m--> 170\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m httpx\u001b[38;5;241m.\u001b[39mHTTPStatusError(\n\u001b[1;32m    171\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mError response \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39mstatus_code\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    172\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mwhile fetching \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mresponse\u001b[38;5;241m.\u001b[39murl\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00merror_message\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    173\u001b[0m         request\u001b[38;5;241m=\u001b[39mresponse\u001b[38;5;241m.\u001b[39mrequest,\n\u001b[1;32m    174\u001b[0m         response\u001b[38;5;241m=\u001b[39mresponse,\n\u001b[1;32m    175\u001b[0m     )\n",
            "\u001b[0;31mHTTPStatusError\u001b[0m: Error response 429 while fetching https://api.mistral.ai/v1/chat/completions: {\"message\":\"Requests rate limit exceeded\"}"
          ]
        }
      ],
      "source": [
        "import os\n",
        "import re\n",
        "from random import randint\n",
        "import networkx as nx\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import nx_arangodb as nxadb\n",
        "\n",
        "from arango import ArangoClient\n",
        "from langgraph.prebuilt import create_react_agent\n",
        "from langgraph.checkpoint.memory import MemorySaver\n",
        "from langchain_openai import ChatOpenAI\n",
        "from langchain_community.graphs import ArangoGraph\n",
        "from langchain_community.chains.graph_qa.arangodb import ArangoGraphQAChain\n",
        "from langchain_core.tools import tool\n",
        "from mistralai import Mistral\n",
        "from langchain_mistralai import ChatMistralAI\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain_core.prompts import ChatPromptTemplate\n",
        "from langchain.chains import create_extraction_chain\n",
        "from langchain_core.messages import HumanMessage, AIMessage\n",
        "\n",
        "# # Connect to ArangoDB\n",
        "# db = ArangoClient(hosts=\"https://d2eeb8083350.arangodb.cloud:8529\").db(\n",
        "#     username=\"root\", password=\"cUZ0YaNdcwfUTw6VjRny\", verify=True\n",
        "# )\n",
        "# arango_graph = ArangoGraph(db)\n",
        "\n",
        "# # Connect to NetworkX representation\n",
        "# G_adb = nxadb.Graph(\n",
        "#     name=\"FlaskRepv1\",\n",
        "#     db=db\n",
        "# )\n",
        "\n",
        "# # Initialize MistralAI LLM\n",
        "# llm = ChatMistralAI(\n",
        "#     model=\"mistral-large-latest\",\n",
        "#     temperature=0,\n",
        "#     max_retries=2,\n",
        "# )\n",
        "\n",
        "# Tool for querying ArangoDB using natural language\n",
        "@tool\n",
        "def text_to_aql_to_text(query: str):\n",
        "    \"\"\"Query the repository graph database using natural language.\n",
        "    This tool translates your query to AQL, executes it, and returns results.\n",
        "    Use for finding files, content, relationships between files, etc.\n",
        "    \"\"\"\n",
        "    chain = ArangoGraphQAChain.from_llm(\n",
        "        llm=llm,\n",
        "        graph=arango_graph,\n",
        "        verbose=True,\n",
        "        allow_dangerous_requests=True\n",
        "    )\n",
        "    result = chain.invoke(query)\n",
        "    return str(result[\"result\"])\n",
        "\n",
        "# Tool for using NetworkX algorithms on the graph\n",
        "@tool\n",
        "def text_to_nx_algorithm_to_text(query: str):\n",
        "    \"\"\"Apply graph algorithms to analyze the repository structure.\n",
        "    This tool is ideal for complex queries like finding dependencies,\n",
        "    centrality of files, or traversal patterns.\n",
        "    \"\"\"\n",
        "    # Generate NetworkX code based on query\n",
        "    text_to_nx = llm.invoke(f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "\n",
        "    Only assume that networkx is installed, and other base python dependencies.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Make sure that `FINAL_RESULT` stores a short & concise answer. Avoid setting this variable to a long sequence.\n",
        "\n",
        "    Your code:\n",
        "    \"\"\").content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    # Execute the generated code\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    try:\n",
        "        exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        FINAL_RESULT = local_vars.get(\"FINAL_RESULT\", \"No result was produced\")\n",
        "    except Exception as e:\n",
        "        return f\"Error executing graph algorithm: {str(e)}\"\n",
        "\n",
        "    # Format the response\n",
        "    nx_to_text = llm.invoke(f\"\"\"\n",
        "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "        I have the following graph analysis query: {query}.\n",
        "\n",
        "        I have executed NetworkX algorithms and the result is: {FINAL_RESULT}\n",
        "\n",
        "        Based on this result, provide a clear and helpful answer to the original query.\n",
        "\n",
        "        Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return nx_to_text\n",
        "\n",
        "# Tool to search file contents for error messages or specific patterns\n",
        "@tool\n",
        "def search_code_for_pattern(pattern: str):\n",
        "    \"\"\"Search through repository files for specific code patterns, error messages,\n",
        "    or function definitions. Returns relevant file sections that match the pattern.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Use AQL to find files that might contain the pattern\n",
        "        query = f\"\"\"\n",
        "        FOR file IN Files\n",
        "            FILTER LIKE(file.content, '%{pattern}%', true)\n",
        "            RETURN {{\n",
        "                filename: file.name,\n",
        "                path: file.path,\n",
        "                matching_content: SUBSTRING(file.content,\n",
        "                                          MAX(0, POSITION(file.content, '{pattern}', true) - 100),\n",
        "                                          MIN(200, LENGTH(file.content) - MAX(0, POSITION(file.content, '{pattern}', true) - 100)))\n",
        "            }}\n",
        "        \"\"\"\n",
        "        cursor = db.aql.execute(query)\n",
        "        results = list(cursor)\n",
        "\n",
        "        if not results:\n",
        "            return f\"No files found containing the pattern '{pattern}'.\"\n",
        "\n",
        "        response = f\"Found {len(results)} file(s) containing '{pattern}':\\n\\n\"\n",
        "        for result in results:\n",
        "            response += f\"File: {result['path']}/{result['filename']}\\n\"\n",
        "            response += f\"Relevant section: ```\\n{result['matching_content']}\\n```\\n\\n\"\n",
        "\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return f\"Error searching for pattern: {str(e)}\"\n",
        "\n",
        "# Tool to find dependencies between files\n",
        "@tool\n",
        "def find_dependencies(file_path: str):\n",
        "    \"\"\"Find which files import or are imported by a specific file.\n",
        "    Useful for understanding dependencies and potential impact of changes.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Find files that this file imports\n",
        "        imports_query = f\"\"\"\n",
        "        FOR v, e IN 1..1 OUTBOUND 'Files/{file_path}' Imports\n",
        "            RETURN {{\n",
        "                imported_file: v.name,\n",
        "                imported_path: v.path,\n",
        "                relationship: 'imported by {file_path}'\n",
        "            }}\n",
        "        \"\"\"\n",
        "        imports_cursor = db.aql.execute(imports_query)\n",
        "        imports = list(imports_cursor)\n",
        "\n",
        "        # Find files that import this file\n",
        "        imported_by_query = f\"\"\"\n",
        "        FOR v, e IN 1..1 INBOUND 'Files/{file_path}' Imports\n",
        "            RETURN {{\n",
        "                importing_file: v.name,\n",
        "                importing_path: v.path,\n",
        "                relationship: 'imports {file_path}'\n",
        "            }}\n",
        "        \"\"\"\n",
        "        imported_by_cursor = db.aql.execute(imported_by_query)\n",
        "        imported_by = list(imported_by_cursor)\n",
        "\n",
        "        response = f\"Dependency analysis for {file_path}:\\n\\n\"\n",
        "\n",
        "        if imports:\n",
        "            response += \"Files imported by this file:\\n\"\n",
        "            for imp in imports:\n",
        "                response += f\"- {imp['imported_path']}/{imp['imported_file']}\\n\"\n",
        "        else:\n",
        "            response += \"This file does not import any other files in the repository.\\n\"\n",
        "\n",
        "        response += \"\\n\"\n",
        "\n",
        "        if imported_by:\n",
        "            response += \"Files that import this file:\\n\"\n",
        "            for imp in imported_by:\n",
        "                response += f\"- {imp['importing_path']}/{imp['importing_file']}\\n\"\n",
        "        else:\n",
        "            response += \"This file is not imported by any other files in the repository.\\n\"\n",
        "\n",
        "        return response\n",
        "    except Exception as e:\n",
        "        return f\"Error finding dependencies: {str(e)}\"\n",
        "\n",
        "# NEW TOOL: Codebase Explainer using graph visualization and analysis\n",
        "@tool\n",
        "def explain_codebase_structure(topic_or_feature: str):\n",
        "    \"\"\"Explain the codebase structure related to a specific topic or feature.\n",
        "    This tool combines graph analysis, file content search, and dependency mapping\n",
        "    to provide a comprehensive explanation of how the code is organized.\n",
        "    \"\"\"\n",
        "    try:\n",
        "        # Step 1: Find relevant files\n",
        "        relevant_files_query = f\"\"\"\n",
        "        FOR file IN Files\n",
        "            FILTER LIKE(file.content, '%{topic_or_feature}%', true)\n",
        "            RETURN {{\n",
        "                id: file._id,\n",
        "                name: file.name,\n",
        "                path: file.path,\n",
        "                type: file.type,\n",
        "                size: file.size\n",
        "            }}\n",
        "        LIMIT 10\n",
        "        \"\"\"\n",
        "        relevant_cursor = db.aql.execute(relevant_files_query)\n",
        "        relevant_files = list(relevant_cursor)\n",
        "\n",
        "        if not relevant_files:\n",
        "            # Try broader search if specific search yields no results\n",
        "            broader_query = f\"\"\"\n",
        "            FOR file IN Files\n",
        "                SORT file.size DESC\n",
        "                RETURN {{\n",
        "                    id: file._id,\n",
        "                    name: file.name,\n",
        "                    path: file.path,\n",
        "                    type: file.type,\n",
        "                    size: file.size\n",
        "                }}\n",
        "            LIMIT 5\n",
        "            \"\"\"\n",
        "            broader_cursor = db.aql.execute(broader_query)\n",
        "            relevant_files = list(broader_cursor)\n",
        "\n",
        "        # Step 2: Find relationships between these files\n",
        "        file_relationships = []\n",
        "        for file in relevant_files:\n",
        "            file_id = file['id']\n",
        "\n",
        "            # Find incoming relationships\n",
        "            in_rel_query = f\"\"\"\n",
        "            FOR v, e IN 1..1 INBOUND '{file_id}' Imports\n",
        "                RETURN {{\n",
        "                    source: v.name,\n",
        "                    source_path: v.path,\n",
        "                    target: '{file['name']}',\n",
        "                    relationship: 'imports'\n",
        "                }}\n",
        "            \"\"\"\n",
        "            in_cursor = db.aql.execute(in_rel_query)\n",
        "            file_relationships.extend(list(in_cursor))\n",
        "\n",
        "            # Find outgoing relationships\n",
        "            out_rel_query = f\"\"\"\n",
        "            FOR v, e IN 1..1 OUTBOUND '{file_id}' Imports\n",
        "                RETURN {{\n",
        "                    source: '{file['name']}',\n",
        "                    source_path: '{file['path']}',\n",
        "                    target: v.name,\n",
        "                    relationship: 'imports'\n",
        "                }}\n",
        "            \"\"\"\n",
        "            out_cursor = db.aql.execute(out_rel_query)\n",
        "            file_relationships.extend(list(out_cursor))\n",
        "\n",
        "        # Step 3: Get code snippets from key files\n",
        "        code_snippets = []\n",
        "        for file in relevant_files[:3]:  # Limit to top 3 files\n",
        "            file_content_query = f\"\"\"\n",
        "            FOR file IN Files\n",
        "                FILTER file._id == '{file['id']}'\n",
        "                RETURN file.content\n",
        "            \"\"\"\n",
        "            content_cursor = db.aql.execute(file_content_query)\n",
        "            content_list = list(content_cursor)\n",
        "\n",
        "            if content_list:\n",
        "                content = content_list[0]\n",
        "                # Extract relevant section containing the topic\n",
        "                if topic_or_feature in content:\n",
        "                    start_pos = max(0, content.find(topic_or_feature) - 200)\n",
        "                    end_pos = min(len(content), content.find(topic_or_feature) + 200)\n",
        "                    relevant_content = content[start_pos:end_pos]\n",
        "                    code_snippets.append({\n",
        "                        \"file\": f\"{file['path']}/{file['name']}\",\n",
        "                        \"snippet\": relevant_content\n",
        "                    })\n",
        "\n",
        "        # Step 4: Generate a comprehensive explanation using the LLM\n",
        "        explanation_prompt = f\"\"\"\n",
        "        I need to explain the structure of a codebase related to \"{topic_or_feature}\".\n",
        "\n",
        "        Here are the relevant files:\n",
        "        {relevant_files}\n",
        "\n",
        "        Here are the relationships between these files:\n",
        "        {file_relationships}\n",
        "\n",
        "        Here are code snippets from key files:\n",
        "        {code_snippets}\n",
        "\n",
        "        Based on this information, provide a clear explanation of:\n",
        "        1. The overall architecture related to {topic_or_feature}\n",
        "        2. How the files interact with each other\n",
        "        3. Key components and their responsibilities\n",
        "        4. How a developer should navigate this part of the codebase\n",
        "\n",
        "        Your explanation should be comprehensive but easy to understand.\n",
        "        \"\"\"\n",
        "\n",
        "        explanation = llm.invoke(explanation_prompt).content\n",
        "\n",
        "        return explanation\n",
        "    except Exception as e:\n",
        "        return f\"Error explaining codebase structure: {str(e)}\"\n",
        "\n",
        "# Create a system prompt for the RAG agent\n",
        "system_template = \"\"\"You are a helpful coding assistant with access to a graph database containing information about a repository's files, folders, and their contents.\n",
        "\n",
        "When a user presents an error or asks for help with a feature, you will:\n",
        "1. Analyze their query to understand what they need\n",
        "2. Use the graph database tools to retrieve relevant information from the repository\n",
        "3. Provide clear solutions or explanations based on the actual code in the repository\n",
        "\n",
        "Repository Schema:\n",
        "{schema}\n",
        "\n",
        "Available tools:\n",
        "- text_to_aql_to_text: Query the graph database in natural language\n",
        "- text_to_nx_algorithm_to_text: Apply graph algorithms to analyze repository structure\n",
        "- search_code_for_pattern: Search code for specific patterns or error messages\n",
        "- find_dependencies: Find relationships between files\n",
        "- explain_codebase_structure: Get a comprehensive explanation of the codebase structure for specific topics or features\n",
        "\n",
        "Answer the user's questions based on the actual repository structure and code.\n",
        "\"\"\"\n",
        "\n",
        "# Create the RAG system\n",
        "tools = [text_to_aql_to_text, text_to_nx_algorithm_to_text, search_code_for_pattern, find_dependencies, explain_codebase_structure]\n",
        "\n",
        "# Updated create_rag_agent function to fix the parameter issue\n",
        "def create_rag_agent():\n",
        "    \"\"\"Create a RAG agent that can query the repository graph database\"\"\"\n",
        "    # Create a template with the schema already processed\n",
        "    formatted_system_message = system_template.format(schema=arango_graph.schema)\n",
        "\n",
        "    # Create the agent directly with the formatted message\n",
        "    agent = create_react_agent(\n",
        "        model=llm,\n",
        "        tools=tools,\n",
        "        prompt=formatted_system_message  # Try using system_message directly\n",
        "    )\n",
        "\n",
        "    return agent\n",
        "# Function to handle user queries\n",
        "def handle_repository_query(user_query):\n",
        "    \"\"\"Process user queries about the repository\"\"\"\n",
        "    agent = create_rag_agent()\n",
        "    result = agent.invoke({\n",
        "        \"messages\": [\n",
        "            {\"role\": \"user\", \"content\": user_query}\n",
        "        ]\n",
        "    })\n",
        "    return result[\"messages\"][-1].content\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample queries to test the system\n",
        "    test_queries = [\n",
        "        \"Explain me the test_tag_interface() function in the codebase?\",\n",
        "    ]\n",
        "\n",
        "    print(\"Repository RAG System Demo\")\n",
        "    print(\"=\" * 50)\n",
        "\n",
        "    for i, query in enumerate(test_queries, 1):\n",
        "        print(f\"\\nTest Query {i}: {query}\")\n",
        "        print(\"-\" * 50)\n",
        "        response = handle_repository_query(query)\n",
        "        print(f\"Response: {response}\")\n",
        "        print(\"=\" * 50)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "id": "IINlJ2XveVM5"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "1) Generating NetworkX code\n",
            "----------\n",
            "import networkx as nx\n",
            "\n",
            "# Assuming G_adb is already defined and loaded with the graph data\n",
            "\n",
            "# Step 1: Identify the node corresponding to the function test_tag_interface()\n",
            "function_name = 'test_tag_interface'\n",
            "function_node = None\n",
            "for node, data in G_adb.nodes(data=True):\n",
            "    if data.get('type') == 'function' and data.get('name') == function_name:\n",
            "        function_node = node\n",
            "        break\n",
            "\n",
            "# Step 2: Use BFS to explore the neighborhood of the function node\n",
            "if function_node:\n",
            "    bfs_tree = nx.bfs_tree(G_adb, source=function_node)\n",
            "    bfs_nodes = list(bfs_tree.nodes)\n",
            "\n",
            "    # Step 3: Collect information about the nodes in the BFS tree\n",
            "    function_info = []\n",
            "    for node in bfs_nodes:\n",
            "        node_data = G_adb.nodes[node]\n",
            "        function_info.append(node_data)\n",
            "\n",
            "    # Step 4: Summarize the information\n",
            "    summary = f\"The function {function_name} is connected to the following nodes: \"\n",
            "    for info in function_info:\n",
            "        summary += f\"{info.get('name')} ({info.get('type')}), \"\n",
            "\n",
            "    FINAL_RESULT = summary.rstrip(', ')\n",
            "else:\n",
            "    FINAL_RESULT = f\"The function {function_name} was not found in the graph.\"\n",
            "----------\n",
            "\n",
            "2) Executing NetworkX code\n",
            "----------\n",
            "FINAL_RESULT: The function test_tag_interface was not found in the graph.\n",
            "----------\n",
            "3) Formulating final answer\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "'The function `test_tag_interface` was not found in the graph. Therefore, I cannot provide an explanation for it based on the current graph data.'"
            ]
          },
          "execution_count": 26,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "text_to_nx_algorithm_to_text(\"Explain me the test_tag_interface() function in the codebase.?\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": 25,
      "metadata": {},
      "outputs": [],
      "source": [
        "def text_to_nx_algorithm_to_text(query):\n",
        "    \"\"\"This tool is available to invoke a NetworkX Algorithm on\n",
        "    the ArangoDB Graph. You are responsible for accepting the\n",
        "    Natural Language Query, establishing which algorithm needs to\n",
        "    be executed, executing the algorithm, and translating the results back\n",
        "    to Natural Language, with respect to the original query.\n",
        "\n",
        "    If the query (e.g traversals, shortest path, etc.) can be solved using the Arango Query Language, then do not use\n",
        "    this tool.\n",
        "    \"\"\"\n",
        "\n",
        "\n",
        "    ######################\n",
        "    print(\"1) Generating NetworkX code\")\n",
        "\n",
        "    text_to_nx = llm.invoke(f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    It is an undirected graph.\n",
        "    \n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "\n",
        "    Only assume that networkx is installed, and other base python dependencies.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Make sure that `FINAL_RESULT` stores a short & consice answer. Avoid setting this variable to a long sequence.\n",
        "\n",
        "    Your code:\n",
        "    \"\"\").content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    print('-'*10)\n",
        "    print(text_to_nx_cleaned)\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"\\n2) Executing NetworkX code\")\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    try:\n",
        "        exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        text_to_nx_final = text_to_nx\n",
        "    except Exception as e:\n",
        "        print(f\"EXEC ERROR: {e}\")\n",
        "        return f\"EXEC ERROR: {e}\"\n",
        "\n",
        "        # TODO: Consider experimenting with a code corrector!\n",
        "        attempt = 1\n",
        "        MAX_ATTEMPTS = 3\n",
        "\n",
        "        # while attempt <= MAX_ATTEMPTS\n",
        "            # ...\n",
        "\n",
        "    print('-'*10)\n",
        "    FINAL_RESULT = local_vars[\"FINAL_RESULT\"]\n",
        "    print(f\"FINAL_RESULT: {FINAL_RESULT}\")\n",
        "    print('-'*10)\n",
        "\n",
        "    ######################\n",
        "\n",
        "    print(\"3) Formulating final answer\")\n",
        "\n",
        "    nx_to_text = llm.invoke(f\"\"\"\n",
        "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "        I have the following graph analysis query: {query}.\n",
        "\n",
        "        I have executed the following python code to help me answer my query:\n",
        "\n",
        "        ---\n",
        "        {text_to_nx_final}\n",
        "        ---\n",
        "\n",
        "        The `FINAL_RESULT` variable is set to the following: {FINAL_RESULT}.\n",
        "\n",
        "        Based on my original Query and FINAL_RESULT, generate a short and concise response to\n",
        "        answer my query.\n",
        "\n",
        "        Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return nx_to_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 30,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the analysis of the NetworkX Graph `G_adb` and the schema provided, it appears that the function `test_tag_interface` was not found in the codebase. This means that there is no node or edge in the graph that corresponds to this function.\n",
            "\n",
            "Here are a few possible reasons for this result:\n",
            "\n",
            "1. **Function Not Present**: The function `test_tag_interface` might not exist in the codebase. It could be that the function was never implemented, or it might be part of a different codebase or version that is not included in the current graph.\n",
            "\n",
            "2. **Naming Convention**: There might be a discrepancy in the naming convention. The function could be named differently in the codebase, or there could be a typo in the query.\n",
            "\n",
            "3. **Graph Incompleteness**: The graph might not be fully populated with all the nodes and edges representing the codebase. This could happen if the graph construction process missed some parts of the codebase.\n",
            "\n",
            "4. **Scope Limitation**: The function might be part of a different module or package that is not included in the current graph schema.\n",
            "\n",
            "To further investigate, you might consider the following steps:\n",
            "\n",
            "- **Verify Function Name**: Double-check the exact name of the function you are looking for. Ensure there are no typos or variations in naming.\n",
            "- **Expand Graph Scope**: Ensure that the graph includes all relevant parts of the codebase. You might need to update the graph construction process to include additional modules or packages.\n",
            "- **Search Alternatives**: Look for similar functions or related functionality in the codebase. There might be other functions that perform similar tasks.\n",
            "\n",
            "If you have access to the codebase, you could also perform a manual search or use other tools to locate the function. If the function is indeed missing, you might need to consult with the development team or review the documentation to understand its intended purpose and implementation.\n"
          ]
        }
      ],
      "source": [
        "\n",
        "# Tool for using NetworkX algorithms on the graph\n",
        "@tool\n",
        "def text_to_nx_algorithm_to_text(query: str):\n",
        "    \"\"\"Apply graph algorithms to analyze the repository structure.\n",
        "    This tool is ideal for complex queries like finding dependencies,\n",
        "    centrality of files, or traversal patterns.\n",
        "    \"\"\"\n",
        "    # Generate NetworkX code based on query\n",
        "    text_to_nx = llm.invoke(f\"\"\"\n",
        "    I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "    I have the following graph analysis query: {query}.\n",
        "\n",
        "    Generate the Python Code required to answer the query using the `G_adb` object.\n",
        "\n",
        "    Be very precise on the NetworkX algorithm you select to answer this query. Think step by step.\n",
        "\n",
        "    Only assume that networkx is installed, and other base python dependencies.\n",
        "\n",
        "    Always set the last variable as `FINAL_RESULT`, which represents the answer to the original query.\n",
        "\n",
        "    Only provide python code that I can directly execute via `exec()`. Do not provide any instructions.\n",
        "\n",
        "    Make sure that `FINAL_RESULT` stores a short & concise answer. Avoid setting this variable to a long sequence.\n",
        "\n",
        "    Your code:\n",
        "    \"\"\").content\n",
        "\n",
        "    text_to_nx_cleaned = re.sub(r\"^```python\\n|```$\", \"\", text_to_nx, flags=re.MULTILINE).strip()\n",
        "\n",
        "    # Execute the generated code\n",
        "    global_vars = {\"G_adb\": G_adb, \"nx\": nx}\n",
        "    local_vars = {}\n",
        "\n",
        "    try:\n",
        "        exec(text_to_nx_cleaned, global_vars, local_vars)\n",
        "        FINAL_RESULT = local_vars.get(\"FINAL_RESULT\", \"No result was produced\")\n",
        "    except Exception as e:\n",
        "        return f\"Error executing graph algorithm: {str(e)}\"\n",
        "\n",
        "    # Format the response\n",
        "    nx_to_text = llm.invoke(f\"\"\"\n",
        "        I have a NetworkX Graph called `G_adb`. It has the following schema: {arango_graph.schema}\n",
        "\n",
        "        I have the following graph analysis query: {query}.\n",
        "\n",
        "        I have executed NetworkX algorithms and the result is: {FINAL_RESULT}\n",
        "\n",
        "        Based on this result, provide a clear and helpful answer to the original query.\n",
        "\n",
        "        Your response:\n",
        "    \"\"\").content\n",
        "\n",
        "    return nx_to_text\n",
        "\n",
        "# Example usage\n",
        "if __name__ == \"__main__\":\n",
        "    # Sample query to test the system\n",
        "    query = \"Explain me the test_tag_interface() function in the codebase.\"\n",
        "    response = text_to_nx_algorithm_to_text(query)\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.16"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
